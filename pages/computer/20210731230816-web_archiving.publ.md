
# Table of Contents



<div class="preview" id="orgf127de7">
<p>
Информация хочет быть сохранённой. Что не скопировано к себе, может исчезнуть. И естественно, «переписчики интернетов», как средневековые переписчики книг, тоже есть, сохраняют то, что кажется достаточно ценным. А тут вот обнаружилось прям заметно инфы об инструментах и сообществе.
</p>

</div>

-   <https://github.com/ArchiveBox/ArchiveBox>, <https://archivebox.io/> - «ArchiveBox is a powerful, self-hosted internet archiving solution to collect, save, and view sites you want to preserve offline. You can set it up as a command-line tool, web app, and desktop app (alpha), on Linux, macOS, and Windows. You can feed it URLs one at a time, or schedule regular imports from browser bookmarks or history, feeds like RSS, bookmark services like Pocket/Pinboard, and more. See input formats for a full list. It saves snapshots of the URLs you feed it in several formats: HTML, PDF, PNG screenshots, WARC, and more out-of-the-box, with a wide variety of content extracted and preserved automatically (article text, audio/video, git repos, etc.). See output formats for a full list. The goal is to sleep soundly knowing the part of the internet you care about will be automatically preserved in durable, easily accessible formats for decades after it goes down».
-   <https://github.com/ArchiveBox/ArchiveBox/wiki/Web-Archiving-Community> - что ещё хорошего есть примерно на эту же тему. И почему это важно.
-   <http://www.tofuproxy.stargrave.org/index.html> - в числе прочего позволяет смотреть WARC -  формат веб-архивов. (Как скачать и установить - в разделе <http://www.tofuproxy.stargrave.org/Usage.html>). Кажется, ВСЁ остальное тут ещё страшнее :)
    -   <https://ru.wikipedia.org/wiki/Web_ARChive> и <https://en.wikipedia.org/wiki/Web_ARChive> - о формате
    -   <https://iipc.github.io/warc-specifications/specifications/warc-zstd/> - спецификация формата
    -   wget умеет делать WARC, по этому поводу имеет опции:
        -   **‘&#x2013;warc-file=file’:** Use file as the destination WARC file.
        -   **‘&#x2013;warc-header=string’:** Use string into as the warcinfo record.
        -   **‘&#x2013;warc-max-size=size’:** Set the maximum size of the WARC files to size.
        -   **‘&#x2013;warc-cdx’:** Write CDX index files.
        -   **‘&#x2013;warc-dedup=file’:** Do not store records listed in this CDX file.
        -   **‘&#x2013;no-warc-compression’:** Do not compress WARC files with GZIP.
        -   **‘&#x2013;no-warc-digests’:** Do not calculate SHA1 digests.
        -   **‘&#x2013;no-warc-keep-log’:** Do not store the log file in a WARC record.
        -   **‘&#x2013;warc-tempdir=dir’:** Specify the location for temporary files created by the WARC writer.
-   <https://rusrim.blogspot.com/search/label/%D1%8D%D0%BB%D0%B5%D0%BA%D1%82%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5%20%D0%B0%D1%80%D1%85%D0%B8%D0%B2%D1%8B> - блог профессионала-архивистки, тег "электронные архивы".
-   <https://tjournal.ru/internet/485405-internet-umer-da-zdravstvuet-internet-kak-vymirayut-ssylki-vremen-nulevyh-i-kto-boretsya-za-ih-sohrannost>
-   <https://wiki.archiveteam.org/index.php/Coronavirus>  - Archive Team — независимая группа людей, которые стоят на страже культурно значимых сайтов — архивируют официальные ресурсы о коронавирусе в странах по всему миру. (via <https://t.me/a_schtsch/90>). «Сейчас, когда государства пытаются балансировать между защитой населения от тяжелых последствий заражения и интересами бизнеса, никто не воспринимает подобные сайты как свидетельства, на это просто нет времени и ресурсов. В первую очередь они — медиа. Но после эпидемии информация о развитии эпидемии, статистика, а также новости об ограничениях — всё это окажется критически важными данными для анализа и самой эпидемии, и реакции на неё. А сайты, как мы знаем, имеют свойство меняться, особенно когда информация "устаревает", кажется ненужной или у источника информационных сообщений меняются приоритеты.» 2022-01-29.
-   <https://github.com/JustAnotherArchivist/snscrape> - сцарапывалка (scraper) соцсетей. Фейсбук, инста, мастодон, реддит, тг, твиттер, вк, weibo. Вроде, вполне внятная инструкция.  
    Уважаемый читатель Ваня, приславший эту ссылку, сопроводил примером применения.
    -   сохранить последние 200 твитов Илона Маска:
        
            snscrape --json --max-results 200 twitter-search "from:elonmusk" > elonmusk.json
        
        Одна строка - один JSON с твитом, в 'content' JSON-а лежит текст твита.
    -   вывести содержимое в удобочитаемом виде:
        
            #!/usr/bin/env python3
            import json
            with open('elonmusk.json') as f:
                for s in f:
            	data = json.loads(s)
            	print(data['content'])
-   <https://t.me/ruarxive> - тг-канал Инфокультуры об архивах «Всё о цифровой архивации, спасении digital-born контента, архивации гибнущих сайтов и иных цифровых объектов».
    -   <https://www.infoculture.ru/> - «хотим распространить концепцию открытых данных, привлечь в сообщество единомышленников и повысить информационную культуру. Поэтому мы занимаемся просветительской деятельностью, создаем и ведем школы открытых данных и выступаем кураторами и советчиками по открытым данным в разных проектах».
        -   Тг-канал <https://t.me/infoculture> - в целом канал Инфокультуры.

